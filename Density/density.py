# -*- coding: utf-8 -*-
"""Density.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iT-uS96S7eJEFtnQPlKkJBixVXuAcdwQ
"""
# Import necessary modules
import os
import cv2
from sahi import AutoDetectionModel
from sahi.predict import get_sliced_prediction
from sahi.utils.cv import read_image
from IPython.display import display, Image
from ultralytics import YOLO
from google.colab.patches import cv2_imshow  # Colab-specific import for displaying images

# Define constants and paths
local_model_path = "/content/density_model.pt"  # Path to the YOLO model in Colab
video_path = "/content/test.mp4"  # Path to the input video
output_path = "/content/output_video.mp4"  # Path to save the output video

# Function to initialize YOLO model
def initialize_yolo_model(model_path):
    model = YOLO(model_path)
    return model


# Function to initialize the SAHI detection model for vehicle density calculation
def initialize_sahi_model(model_path):
    detection_model = AutoDetectionModel.from_pretrained(
        model_type="yolov8",
        model_path=model_path,
        confidence_threshold=0.25,
        device="cuda:0"  # Change to 'cpu' if GPU is not available
    )
    return detection_model


# Function to initialize video capture and writer
def initialize_video(video_path, output_path):
    cap = cv2.VideoCapture(video_path)

    if not cap.isOpened():
        print("Error: Could not open video.")
        cap.release()
        exit()

          # Video Writer Initialization
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for .mp4 file
    fps = cap.get(cv2.CAP_PROP_FPS)  # Frames per second from the input video
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))

    return cap, out

# Function to process each frame for vehicle detection and density calculation
def process_frame(frame, detection_model, car_indices, weights):
    # Convert the current frame to appropriate format for SAHI processing
    frame_path = "/content/current_frame.jpg"
    cv2.imwrite(frame_path, frame)

    # Get sliced predictions using SAHI
    result = get_sliced_prediction(
        frame_path,
        detection_model,
        slice_height=256,
        slice_width=256,
        overlap_height_ratio=0.2,
        overlap_width_ratio=0.2
    )

    # Filter for Vehicle Classes
    vehicle_preds = [pred for pred in result.object_prediction_list if pred.category.id in car_indices]

    # Update the result object to contain only vehicle predictions
    result.object_prediction_list = vehicle_preds

    # Draw Bounding Boxes and Calculate Density
    density_sum = 0.0  # Initialize density sum for each frame

    for pred in vehicle_preds:
        # Extract the bounding box coordinates
        bbox = pred.bbox
        category_name = pred.category.name
        score = pred.score.value

        # Draw bounding box
        start_point = (int(bbox.minx), int(bbox.miny))
        end_point = (int(bbox.maxx), int(bbox.maxy))
        color = (0, 255, 0)  # Green color for bounding boxes
        thickness = 1
        cv2.rectangle(frame, start_point, end_point, color, thickness)

        # Add label with category name and score
        label = f"{category_name}: {score:.2f}"
        label_position = (int(bbox.minx), int(bbox.miny) - 10)
        font_scale = 0.3
        cv2.putText(frame, label, label_position, cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness)

        # Calculate density as the sum of weights
        density_sum += weights.get(category_name, 0)  # Default to 0 if class not found

    # Display density on the frame
    density_text = f"Density: {density_sum:.2f} (weighted sum of vehicles)"
    cv2.putText(frame, density_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

    return frame

# Main function to process the entire video
def process_video():
    # Step 1: Initialize Models
    yolo_model = initialize_yolo_model(local_model_path)
    detection_model = initialize_sahi_model(local_model_path)

    # Step 2: Get Class Indices for Vehicle Types
    class_names = detection_model.model.model.names
    vehicle_classes = ['car', 'bus', 'motorcycle']
    car_indices = [key for key, value in class_names.items() if value in vehicle_classes]

    # Step 3: Initialize Video Capture and Writer
    cap, out = initialize_video(video_path, output_path)

    # Vehicle weights for traffic density calculation
    weights = {'car': 1.0, 'bus': 2.0, 'motorcycle': 0.5}

    # Step 4: Frame-by-Frame Processing of Video
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break  # Exit if there are no more frames

        # Process the current frame
        processed_frame = process_frame(frame, detection_model, car_indices, weights)

        # Write the processed frame to the output video file
        out.write(processed_frame)

        # Step 5: Display the Frame using cv2_imshow()
        cv2_imshow(processed_frame)  # Colab-specific function to display frames

    # Release video capture and writer objects
    cap.release()
    out.release()
    cv2.destroyAllWindows()

    print(f"Processed video saved to: {output_path}")

# Execute the video processing
if __name__ == "__main__":
   process_video()

